---
timezone: UTC+8
---

> 请在上边的 timezone 添加你的当地时区(UTC)，这会有助于你的打卡状态的自动化更新，如果没有添加，默认为北京时间 UTC+8 时区


# Bitpeng-YT

1. 自我介绍
一个努力扎根web3的大学生

2. 你认为你会完成本次残酷学习吗？
会的

3. 你的联系方式（推荐 Telegram）
@Web3CartonNinja

## Notes

<!-- Content_START -->

### 2025.06.01

笔记内容
今天学习 Language Agents: Foundations, Prospects, and Risks (Slides)
 (了解LLM Agent的基本构成、潜力与风险)

1、LLM 与 agent 结合的两种思路
  a. LLM-first —— 把大语言模型（LLM）直接做成一个“智能体”
  含义：在 LLM 之上搭建“脚手架”，以提示为核心，工程量较大
  逻辑：即直接把大语言模型当作“智能体”的大脑，所有决策、推理、行动都由 LLM 来驱动

  b. Agent-first —— 将 LLM 整合到 AI 智能体中，让它们能够使用自然语言进行推理和交流
  含义：与以往其它 AI 智能体面临的挑战（如感知、推理、世界模型、规划）基本相同，但需要从 LLM 的新视角重新审视这些挑战，并解决一些新的问题（如：合成数据、自我反思、内在搜索）
  逻辑：先设计一个完整的“智能体框架”（包括感知、决策、规划、世界状态维护等模块），然后把 LLM 作为其中擅长“语言推理”和“沟通”的一环来使用

2、现在的AI 智能体，借助集成的 LLM，可以用“语言”作为推理和交流的媒介。
  a. 今时不同往日
  过去的 AI 智能体，如果要做推理和决策，往往需要在感知、状态估计、规划等模块之间编写复杂的代码，各个模块高度定制化。
  现在，只要把强大的 LLM 嵌进智能体体系里，就能让“语言”直接承担很多曾经需要专门算法才能完成的内部推理过程。

  b. “语言”在当代 AI 智能体中扮演的角色
  遵循的指令：LLM 能够理解自然语言指令并按要求执行。
  上下文学习：在同一次会话的上下文中，模型可以根据已知示例自我“学习”或“调整”输出风格，而无需重新训练。
  定制化输出：可以根据用户需求灵活地改变回复格式、口吻、细节层次等。
  内在推理能力：LLM 在生成文字的过程中，实际上是在内部连续不断地做推断，比如“当前状态是什么”“下一步该怎么做才合理”“我刚才的结论有没有问题”等。

3、“语言智能体”（Language agents）
  - 含义：指一类以“自然语言”为核心手段来进行推理和交流的 AI 智能体。
  - 与传统只能处理数值/符号化信息的智能体不同，“语言智能体”把“说话/写作”看作与“感知”、“行动”同等重要且不可或缺的“能力”
  - 无论它是“只用语言”（纯 LLM agent）、还是“多模态＋语言”（multimodal agent），甚至未来会出现新的架构，只要“语言”始终是推理与对话的主战场，就可以称其为“语言智能体”。
  - 当前 LLM 只是实现语言智能体的主要方式，但并非绝对唯一；未来可能出现替代或补充的技术，但“智能体需要通用语言能力”这件事，会长久存在。

4、AI 智能体的演进
  - 路线：逻辑智能体（Logical Agent） → 神经网络智能体（Neural Agent） → 语言智能体（Language Agent）
  - 表现力进步
   “逻辑智能体”受制于【逻辑语言】本身所能表达的范围；“神经网络智能体”可以编码为神经网络能够表示的任何事物，但仍有限制；“语言智能体”几乎可以表达“世界上任何东西”，尤其是那些能够“用语言描述”的部分
  - 推理方式进步
   “逻辑智能体”有【完备性】和【显式规则】保障、结果可预测、但很僵化；“神经网络智能体”随机性较高（stochastic）、“黑箱式”隐含（implicit），同样也比较死板（rigid）——因为一旦训练好，网络权重固定，推理模式也就固定了；“语言智能体”虽然推理链条可以用文字或 token 来展现，但并非像传统符号逻辑那样 100% 可追踪到每一步规则，而是介于“显式符号逻辑”和“黑箱神经网络”之间，能兼容多种上下文、变通各种推理方式，容易对话式地进行自我调整。

### 2025.06.02

笔记内容
今天学习论文 《How Far Are We From AGI: Are LLMs All We Need?》 的第 2、3 两节，AGI 的内部结构和 AGI 的接口

- **论文整体结构**
  - 核心 AGI 组件的讨论：涵盖 AGI 内部（§ 2）、AGI 接口（§ 3）和 AGI 系统（§ 4）
  - AGI 对齐技术（§ 5）
  - AGI 路线图：包括 AGI 评估（6.2）、如何达到下一个 AGI 水平（6.3）、“我们距离 AGI 还有多远” 研讨会讨论（6.4）、AGI 路线图的其他视角（6.5）
  - 案例研究（§ 7）
   
- **AGI 的内部结构**
  - 知识表示与存储
  - 推理机制
  - 自主学习能力
   
- **AGI 交互接口**
  - 数字接口
  - 物理接口
  - 智能接口
  
### 2025.06.03

笔记内容
今天学习论文 《How Far Are We From AGI: Are LLMs All We Need?》 的第 4 节，AGI 系统

- **AGI 系统**
  - 系统挑战（System Challenges）
      - 讨论构建完整 AGI 系统时面临的关键障碍：如多模态融合（整合文本、图像、音频等不同模态数据）、长期记忆存储、动态决策能力等。
      - 重点关注如何设计能同时处理认知、推理和行动的统一框架。

  - 可扩展模型架构（Scalable Model Architectures）
      - 分析支持 AGI 规模的神经网络架构：如 Transformer 变体（支持万亿参数级）、MoE（Mixture of Experts）架构等。
      - 强调架构需具备动态扩展能力，能通过新增模块灵活应对新任务。
  - 大规模训练（Large-scale Training）
      - 技术重点：分布式训练（如 Megatron-LM、DeepSpeed 框架）、梯度优化算法、灾难性遗忘缓解。
      - 数据策略：跨领域预训练、自监督学习、合成数据生成。
  - 推理技术（Inference Techniques）
      - 核心方法：思维链（CoT）、程序辅助推理（Program-aided Reasoning）、神经符号系统。
      - 优化方向：降低延迟（如模型量化）、提升多步推理稳定性。
  - 成本与效率（Cost and Efficiency）
      - 量化 AGI 系统开发的资源需求：千卡级 GPU 集群、PB 级数据、百万美元级训练成本。
      - 探讨模型压缩（蒸馏 / 剪枝）和硬件协同设计（如 TPUv5）的优化路径。

### 2025.06.04

### 2025.06.05

### 2025.06.06



<!-- Content_END -->
